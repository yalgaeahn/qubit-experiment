{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10cd6c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck\n",
      "LOADED: ./qpu_parameters/20260211-2256_2q_qst\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "from laboneq.contrib.example_helpers.generate_descriptor import generate_descriptor\n",
    "#from laboneq.contrib.example_helpers.generate_device_setup import generate_device_setup\n",
    "from laboneq.dsl.device import DeviceSetup\n",
    "from laboneq.simple import *\n",
    "from laboneq.dsl.device import DeviceSetup\n",
    "from laboneq.dsl.calibration import Oscillator, SignalCalibration\n",
    "from laboneq.dsl.enums import ModulationType\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# descriptor = generate_descriptor(\n",
    "#     #pqsc=[\"\"], # 장비 여러개 사용시\n",
    "#     shfqc_6=[\"DEV12256\"], \n",
    "#     number_data_qubits=3,\n",
    "#     multiplex=True,\n",
    "#     number_multiplex=6,\n",
    "#     include_cr_lines=False,\n",
    "#     include_ef_lines=True,\n",
    "#     get_zsync=False,  # Only set to True when using real device\n",
    "#     save = True,\n",
    "#     filename=\"1port\",\n",
    "#     ip_address=\"192.168.0.83\"\n",
    "# )\n",
    "\n",
    "\n",
    "#descriptor\n",
    "#setup = DeviceSetup.from_descriptor(yaml_text=descriptor, server_host=\"192.168.0.83\")\n",
    "setup = DeviceSetup.from_yaml(filepath=\"/Users/yalgaeahn/JSAHN/qubit-experiment/examples/selectiveRIP/Descriptors/1port.yaml\" , server_host=\"192.168.0.83\")\n",
    "#setup\n",
    "setup.instruments[0].device_options = 'SHFQC/PLUS/QC6CH'\n",
    "#setup.instruments\n",
    "\n",
    "\n",
    "bus_ids = [f\"b{i}\" for i in range(3)]\n",
    "bus_port = [4,5,6] #used 1,2,3 for qubit drive\n",
    "\n",
    "for i, bus in zip(bus_port,bus_ids):\n",
    "    setup.add_connections(\n",
    "        setup.instruments[0].uid,\n",
    "        # each bus uses its own drive:\n",
    "        create_connection(\n",
    "            to_signal=f\"{bus}/drive\",\n",
    "            ports=f\"SGCHANNELS/{i}/OUTPUT\"\n",
    "        ))\n",
    "\n",
    "# Calibrate qubit drive/measure lines for oscillator phase increments\n",
    "qubit_ids = [uid for uid in setup.logical_signal_groups if uid.startswith(\"q\")]\n",
    "for qubit in qubit_ids:\n",
    "    for line, frequency, mod_type in [\n",
    "        (\"drive\", 5e9, ModulationType.HARDWARE),\n",
    "        (\"drive_ef\", 6e9, ModulationType.HARDWARE),\n",
    "        (\"measure\", 4e9, ModulationType.SOFTWARE),\n",
    "    ]:\n",
    "        logical_signal = setup.logical_signal_by_uid(f\"{qubit}/{line}\")\n",
    "        oscillator = Oscillator(modulation_type=mod_type)\n",
    "        logical_signal.calibration = SignalCalibration(\n",
    "            local_oscillator=Oscillator(frequency=frequency),\n",
    "            oscillator=oscillator,\n",
    "        )\n",
    "        if line == \"measure\":\n",
    "            acquire_signal = setup.logical_signal_by_uid(f\"{qubit}/acquire\")\n",
    "            acquire_signal.calibration = SignalCalibration(\n",
    "                local_oscillator=Oscillator(frequency=frequency),\n",
    "                oscillator=oscillator,\n",
    "            )\n",
    "\n",
    "from qpu_types.fixed_transmon import FixedTransmonQubit, FixedTransmonQubitParameters\n",
    "from qpu_types.bus_cavity import BusCavity, BusCavityParameters\n",
    "from qpu_types.fixed_transmon.operations import FixedTransmonOperations\n",
    "from qpu_types.bus_cavity.operations import BusCavityOperations\n",
    "from laboneq.dsl.quantum.qpu import QPU, QuantumPlatform\n",
    "from helper import load_qubit_parameters, save_qubit_parameters\n",
    "\n",
    "qubit_uids = [uid for uid in setup.logical_signal_groups if uid.startswith(\"q\")]\n",
    "bus_uids = [uid for uid in setup.logical_signal_groups if uid.startswith(\"b\")]\n",
    "\n",
    "qubits = FixedTransmonQubit.from_device_setup(\n",
    "    setup, qubit_uids=qubit_uids)\n",
    "buses = BusCavity.from_device_setup(\n",
    "    setup, qubit_uids=bus_uids)\n",
    "\n",
    "qpu = QPU(quantum_elements={\"qubits\" : qubits, \"bus\" : buses}, quantum_operations=[FixedTransmonOperations, BusCavityOperations])\n",
    "\n",
    "\n",
    "# from laboneq.simple import workflow\n",
    "# folder_store = workflow.logbook.FolderStore(\"./experiment_store\") \n",
    "# folder_store.activate()\n",
    "# #folder_store.deactivate()\n",
    "# #workflow.logbook.LoggingStore().activate()\n",
    "# #workflow.logbook.LogbookStore().deactivate()\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "def find_latest_json(folder_path):\n",
    "    files = [f for f in os.listdir(folder_path)]\n",
    "    timestamps = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            # Extract a timestamp assuming it's included in the filename\n",
    "            timestamp_str = file.split('_', 1)[0]  # Assuming YYYYMMDDHHMMSS format\n",
    "            timestamp = datetime.strptime(timestamp_str, '%Y%m%d-%H%M%S')\n",
    "            timestamps.append((timestamp, file))\n",
    "        except ValueError:\n",
    "            print(\"fuck\")\n",
    "            continue  # Skip files that do not match the timestamp format\n",
    "\n",
    "       # Find the most recent file\n",
    "    if timestamps:\n",
    "        latest_file = max(timestamps, key=lambda x: x[0])[1]\n",
    "        return os.path.join(folder_path, latest_file)\n",
    "    return None\n",
    "\n",
    "qb_pars_file = find_latest_json(\"./qpu_parameters/\")\n",
    "print(f\"LOADED: {qb_pars_file}\")\n",
    "\n",
    "from qpu_types.fixed_transmon.operations import FixedTransmonOperations\n",
    "from qpu_types.bus_cavity.operations import BusCavityOperations\n",
    "import laboneq.dsl.quantum.qpu as qpu_mod\n",
    "\n",
    "class CombinedOperations(FixedTransmonOperations, BusCavityOperations):\n",
    "    pass\n",
    "\n",
    "qpu_mod.CombinedOperations = CombinedOperations\n",
    "\n",
    "qpu = load(qb_pars_file)\n",
    "\n",
    "buses = qpu.groups.bus\n",
    "qubits = qpu.groups.qubits\n",
    "\n",
    "\n",
    "from laboneq.simple import workflow\n",
    "folder_store = workflow.logbook.FolderStore(\"./experiment_store\")\n",
    "folder_store.activate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f15de",
   "metadata": {},
   "source": [
    "# CONNECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fede057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026.02.13 01:22:53.104] INFO    Logging initialized from [Default inline config in laboneq.laboneq_logging] logdir is /Users/yalgaeahn/JSAHN/qubit-experiment/examples/selectiveRIP/laboneq_output/log\n",
      "[2026.02.13 01:22:53.105] INFO    VERSION: laboneq 25.10.3\n",
      "[2026.02.13 01:22:53.106] INFO    Connecting to data server at 192.168.0.83:8004\n",
      "[2026.02.13 01:22:53.148] INFO    Connected to Zurich Instruments LabOne Data Server version 25.10.1.4 at 192.168.0.83:8004\n",
      "[2026.02.13 01:22:53.188] INFO    Configuring the device setup\n",
      "[2026.02.13 01:22:53.234] INFO    The device setup is configured\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<laboneq.dsl.session.ConnectionState at 0x13c988050>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from laboneq.simple import Session\n",
    "session = Session(setup)\n",
    "session.connect(ignore_version_mismatch=False, do_emulation=False)\n",
    "#session.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964259db",
   "metadata": {},
   "source": [
    "# 정리된 Readout 최적화 흐름\n",
    "\n",
    "1) Readout frequency (coarse sweep, wide)\n",
    "2) Integration window (delay+length sweep)\n",
    "3) Readout length sweep\n",
    "4) Readout frequency (re-sweep, tighter)\n",
    "5) Readout amplitude sweep\n",
    "6) Readout frequency (final short convergence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d68056c",
   "metadata": {},
   "source": [
    "# Dispersive Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4178d19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from experiments import dispersive_shift\n",
    "\n",
    "#######################################################################\n",
    "q = qubits[0]\n",
    "temporary_parameters = {}\n",
    "temp_pars =deepcopy(q.parameters)\n",
    "temporary_parameters[q.uid] = temp_pars\n",
    "\n",
    "print(f\"DRIVE range (dBm) : {q.parameters.drive_range}, READOUT range (dBm) : {q.parameters.readout_range_out}\")\n",
    "#######################################################################\n",
    "options = dispersive_shift.experiment_workflow.options()\n",
    "options.count(1024)\n",
    "options.update(False)\n",
    "#print(workflow.show_fields(options))\n",
    "\n",
    "###################################################################\n",
    "dispersive = dispersive_shift.experiment_workflow(\n",
    "    session=session,\n",
    "    qpu=qpu,\n",
    "    qubit=q,\n",
    "    frequencies=q.parameters.readout_resonator_frequency + np.linspace(-5e6,5e6,201),\n",
    "    options=options,\n",
    "    states='ge',\n",
    "    temporary_parameters=temporary_parameters\n",
    ")\n",
    "\n",
    "dispersive_result = dispersive.run() \n",
    "print(dispersive_result.tasks['analysis_workflow'].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4249a27",
   "metadata": {},
   "source": [
    "# Converged Readout Optimization\n",
    "\n",
    "목표 순서: `frequency → integration window(delay+length) → readout length → frequency re-sweep → amplitude → short frequency re-sweep`\n",
    "\n",
    "아래 셀은 이전 1~4 스텝을 한 번에 묶은 실행 예시입니다. 각 스텝은 직전 결과의 최적값을 다음 스텝의 `temporary_parameters`로 넘겨서 수렴 형태로 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3095a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "\n",
    "from experiments import (\n",
    "    readout_frequency_sweep,\n",
    "    readout_integration_delay_sweep,\n",
    "    readout_length_sweep,\n",
    "    readout_amplitude_sweep,\n",
    ")\n",
    "\n",
    "\n",
    "def _safe_output_unwrap(obj):\n",
    "    cur = obj\n",
    "    for _ in range(64):\n",
    "        if cur is None:\n",
    "            return None\n",
    "        if isinstance(cur, dict) and \"analysis_result\" in cur and cur[\"analysis_result\"] is not None:\n",
    "            cur = cur[\"analysis_result\"]\n",
    "            continue\n",
    "        if hasattr(cur, \"output\"):\n",
    "            cur = cur.output\n",
    "            continue\n",
    "        return cur\n",
    "    return cur\n",
    "\n",
    "\n",
    "def extract_analysis_output(workflow_result):\n",
    "    # 1) result-like wrappers\n",
    "    out = _safe_output_unwrap(workflow_result)\n",
    "    if isinstance(out, dict) and \"best_point\" in out:\n",
    "        return out\n",
    "\n",
    "    # 2) fallback: tasks map/list scan\n",
    "    tasks = getattr(workflow_result, \"tasks\", None)\n",
    "    if tasks is not None:\n",
    "        try:\n",
    "            iterable = tasks.values() if hasattr(tasks, \"values\") else tasks\n",
    "            for t in iterable:\n",
    "                candidate = _safe_output_unwrap(getattr(t, \"output\", None))\n",
    "                if isinstance(candidate, dict) and \"analysis_result\" in candidate:\n",
    "                    candidate = _safe_output_unwrap(candidate[\"analysis_result\"])\n",
    "                if isinstance(candidate, dict) and \"best_point\" in candidate:\n",
    "                    return candidate\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    raise RuntimeError(\"Could not extract analysis output containing best_point.\")\n",
    "\n",
    "\n",
    "def _make_temp_params(qubit, state):\n",
    "    temp = deepcopy(qubit.parameters)\n",
    "    for k, v in state.items():\n",
    "        if hasattr(temp, k):\n",
    "            setattr(temp, k, v)\n",
    "    return {qubit.uid: temp}\n",
    "\n",
    "\n",
    "def _q_state_from_qubit(qubit):\n",
    "    return {\n",
    "        \"readout_resonator_frequency\": float(qubit.parameters.readout_resonator_frequency),\n",
    "        \"readout_integration_delay\": float(qubit.parameters.readout_integration_delay or 0.0),\n",
    "        \"readout_integration_length\": float(qubit.parameters.readout_integration_length),\n",
    "        \"readout_length\": float(qubit.parameters.readout_length),\n",
    "        \"readout_amplitude\": float(qubit.parameters.readout_amplitude),\n",
    "    }\n",
    "\n",
    "\n",
    "def _append_history(history, step, analysis, detail, q):\n",
    "    uid = q.uid\n",
    "    best = analysis[\"best_point\"]\n",
    "    history.append(\n",
    "        {\n",
    "            \"step\": step,\n",
    "            \"quality\": analysis[\"quality_flag\"],\n",
    "            \"detail\": detail,\n",
    "            \"best_point\": best,\n",
    "            \"new_parameter_values\": analysis[\"new_parameter_values\"].get(uid, {}),\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "def run_readout_converged_workflow(\n",
    "    q,\n",
    "    qpu,\n",
    "    session,\n",
    "    *,\n",
    "    state=None,\n",
    "    freq_span_initial=1.0e6,\n",
    "    freq_points_initial=13,\n",
    "    freq_span_mid=250e3,\n",
    "    freq_points_mid=11,\n",
    "    freq_span_short=80e3,\n",
    "    freq_points_short=9,\n",
    "    window_delay_span=30e-9,\n",
    "    window_length_factors=(0.7, 0.85, 1.0, 1.15, 1.3),\n",
    "    readout_lengths=(0.5, 0.7, 0.9, 1.0, 1.2, 1.4),\n",
    "    amp_frac=0.2,\n",
    "    amp_points=13,\n",
    "    count_freq=1024,\n",
    "    count_other=512,\n",
    "    do_plot=True,\n",
    "    plot_iq_cloud=True,\n",
    "):\n",
    "    if state is None:\n",
    "        state = _q_state_from_qubit(q)\n",
    "\n",
    "    history = []\n",
    "\n",
    "    # 1) frequency (coarse)\n",
    "    center_f = state[\"readout_resonator_frequency\"]\n",
    "    freqs = np.linspace(center_f - freq_span_initial, center_f + freq_span_initial, freq_points_initial)\n",
    "    opts = readout_frequency_sweep.experiment_workflow.options()\n",
    "    opts.do_analysis(True)\n",
    "    opts.update(False)\n",
    "    opts.count(int(count_freq))\n",
    "    if not do_plot:\n",
    "        opts.do_plotting(False)\n",
    "\n",
    "    wf = readout_frequency_sweep.experiment_workflow(\n",
    "        session=session,\n",
    "        qpu=qpu,\n",
    "        qubit=q,\n",
    "        frequencies=freqs,\n",
    "        temporary_parameters=_make_temp_params(q, state),\n",
    "        options=opts,\n",
    "    )\n",
    "    ana = extract_analysis_output(wf.run())\n",
    "    best = ana[\"new_parameter_values\"][q.uid]\n",
    "    state.update({\"readout_resonator_frequency\": float(best[\"readout_resonator_frequency\"])})\n",
    "    _append_history(history, \"freq-coarse\", ana, f\"center={center_f:.6f}Hz ± {freq_span_initial:.0f}Hz\", q)\n",
    "\n",
    "    # 2) integration delay + integration length window\n",
    "    center_delay = state[\"readout_integration_delay\"]\n",
    "    center_length = state[\"readout_integration_length\"]\n",
    "    delays = np.linspace(max(0.0, center_delay - window_delay_span), center_delay + window_delay_span, 13)\n",
    "    integration_lengths = np.asarray(window_length_factors, dtype=float) * center_length\n",
    "\n",
    "    opts = readout_integration_delay_sweep.experiment_workflow.options()\n",
    "    opts.do_analysis(True)\n",
    "    opts.update(False)\n",
    "    opts.count(int(count_other))\n",
    "    if not do_plot:\n",
    "        opts.do_plotting(False)\n",
    "\n",
    "    wf = readout_integration_delay_sweep.experiment_workflow(\n",
    "        session=session,\n",
    "        qpu=qpu,\n",
    "        qubit=q,\n",
    "        delays=delays,\n",
    "        integration_lengths=integration_lengths,\n",
    "        temporary_parameters=_make_temp_params(q, state),\n",
    "        options=opts,\n",
    "    )\n",
    "    ana = extract_analysis_output(wf.run())\n",
    "    best = ana[\"new_parameter_values\"][q.uid]\n",
    "    state.update(\n",
    "        {\n",
    "            \"readout_integration_delay\": float(best[\"readout_integration_delay\"]),\n",
    "            \"readout_integration_length\": float(best[\"readout_integration_length\"]),\n",
    "        }\n",
    "    )\n",
    "    _append_history(history, \"integration-window\", ana, \"simultaneous sweep\", q)\n",
    "\n",
    "    # 3) readout length\n",
    "    base_len = state[\"readout_length\"]\n",
    "    readout_length_points = np.asarray(readout_lengths, dtype=float) * base_len\n",
    "    opts = readout_length_sweep.experiment_workflow.options()\n",
    "    opts.do_analysis(True)\n",
    "    opts.update(False)\n",
    "    opts.count(int(count_other))\n",
    "    if not do_plot:\n",
    "        opts.do_plotting(False)\n",
    "\n",
    "    wf = readout_length_sweep.experiment_workflow(\n",
    "        session=session,\n",
    "        qpu=qpu,\n",
    "        qubit=q,\n",
    "        readout_lengths=readout_length_points,\n",
    "        temporary_parameters=_make_temp_params(q, state),\n",
    "        options=opts,\n",
    "    )\n",
    "    ana = extract_analysis_output(wf.run())\n",
    "    best = ana[\"new_parameter_values\"][q.uid]\n",
    "    state.update({\"readout_length\": float(best[\"readout_length\"])})\n",
    "    _append_history(history, \"readout-length\", ana, f\"scaled factors={tuple(readout_lengths)}\", q)\n",
    "\n",
    "    # 4) re-sweep frequency around updated point\n",
    "    center_f = state[\"readout_resonator_frequency\"]\n",
    "    freqs = np.linspace(center_f - freq_span_mid, center_f + freq_span_mid, freq_points_mid)\n",
    "    opts = readout_frequency_sweep.experiment_workflow.options()\n",
    "    opts.do_analysis(True)\n",
    "    opts.update(False)\n",
    "    opts.count(int(count_freq))\n",
    "    if not do_plot:\n",
    "        opts.do_plotting(False)\n",
    "    if not plot_iq_cloud:\n",
    "        opts.do_plotting_optimal_iq_cloud(False)\n",
    "\n",
    "    wf = readout_frequency_sweep.experiment_workflow(\n",
    "        session=session,\n",
    "        qpu=qpu,\n",
    "        qubit=q,\n",
    "        frequencies=freqs,\n",
    "        temporary_parameters=_make_temp_params(q, state),\n",
    "        options=opts,\n",
    "    )\n",
    "    ana = extract_analysis_output(wf.run())\n",
    "    best = ana[\"new_parameter_values\"][q.uid]\n",
    "    state.update({\"readout_resonator_frequency\": float(best[\"readout_resonator_frequency\"])})\n",
    "    _append_history(history, \"freq-refine-1\", ana, f\"center={center_f:.6f}Hz ± {freq_span_mid:.0f}Hz\", q)\n",
    "\n",
    "    # 5) readout amplitude\n",
    "    base_amp = state[\"readout_amplitude\"]\n",
    "    amp_span = max(0.05, abs(base_amp) * amp_frac)\n",
    "    amp_lo = max(0.0, base_amp - amp_span)\n",
    "    amp_hi = min(1.0, base_amp + amp_span)\n",
    "    if np.isclose(amp_lo, amp_hi):\n",
    "        amp_lo = max(0.0, base_amp - 0.02)\n",
    "        amp_hi = min(1.0, base_amp + 0.02)\n",
    "        if np.isclose(amp_lo, amp_hi):\n",
    "            amp_lo = max(0.0, base_amp * 0.8)\n",
    "            amp_hi = min(1.0, base_amp * 1.2)\n",
    "\n",
    "    amplitudes = np.linspace(amp_lo, amp_hi, amp_points)\n",
    "    opts = readout_amplitude_sweep.experiment_workflow.options()\n",
    "    opts.do_analysis(True)\n",
    "    opts.update(False)\n",
    "    opts.count(int(count_freq))\n",
    "    if not do_plot:\n",
    "        opts.do_plotting(False)\n",
    "\n",
    "    wf = readout_amplitude_sweep.experiment_workflow(\n",
    "        session=session,\n",
    "        qpu=qpu,\n",
    "        qubit=q,\n",
    "        amplitudes=amplitudes,\n",
    "        temporary_parameters=_make_temp_params(q, state),\n",
    "        options=opts,\n",
    "    )\n",
    "    ana = extract_analysis_output(wf.run())\n",
    "    best = ana[\"new_parameter_values\"][q.uid]\n",
    "    state.update({\"readout_amplitude\": float(best[\"readout_amplitude\"])})\n",
    "    _append_history(history, \"amplitude\", ana, f\"sweep={amp_lo:.4f} ~ {amp_hi:.4f}\", q)\n",
    "\n",
    "    # 6) final short frequency refinement\n",
    "    center_f = state[\"readout_resonator_frequency\"]\n",
    "    freqs = np.linspace(center_f - freq_span_short, center_f + freq_span_short, freq_points_short)\n",
    "    opts = readout_frequency_sweep.experiment_workflow.options()\n",
    "    opts.do_analysis(True)\n",
    "    opts.update(False)\n",
    "    opts.count(int(count_freq))\n",
    "    if not do_plot:\n",
    "        opts.do_plotting(False)\n",
    "    if not plot_iq_cloud:\n",
    "        opts.do_plotting_optimal_iq_cloud(False)\n",
    "\n",
    "    wf = readout_frequency_sweep.experiment_workflow(\n",
    "        session=session,\n",
    "        qpu=qpu,\n",
    "        qubit=q,\n",
    "        frequencies=freqs,\n",
    "        temporary_parameters=_make_temp_params(q, state),\n",
    "        options=opts,\n",
    "    )\n",
    "    ana = extract_analysis_output(wf.run())\n",
    "    best = ana[\"new_parameter_values\"][q.uid]\n",
    "    state.update({\"readout_resonator_frequency\": float(best[\"readout_resonator_frequency\"])})\n",
    "    _append_history(history, \"freq-refine-2\", ana, f\"center={center_f:.6f}Hz ± {freq_span_short:.0f}Hz\", q)\n",
    "\n",
    "    return state, history\n",
    "\n",
    "\n",
    "def _print_history(history):\n",
    "    for idx, item in enumerate(history, 1):\n",
    "        best = item[\"best_point\"]\n",
    "        print(f\"[{idx}] {item['step']:18s} quality={item['quality']:>14s} detail={item['detail']}\")\n",
    "        for k, v in best.items():\n",
    "            if isinstance(v, (int, float)):\n",
    "                print(f\"    {k}: {v}\")\n",
    "        print(f\"    updated: {item['new_parameter_values']}\")\n",
    "\n",
    "\n",
    "q = qubits[0]\n",
    "state0 = _q_state_from_qubit(q)\n",
    "print(\"initial state:\")\n",
    "pprint(state0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1837636",
   "metadata": {},
   "source": [
    "## Run one converged optimization pass (예시): `freq -> window -> length -> freq -> amp -> freq(짧게)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7522e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "readout_state, readout_history = run_readout_converged_workflow(\n",
    "    q=q,\n",
    "    qpu=qpu,\n",
    "    session=session,\n",
    "    state=state0,\n",
    "    freq_span_initial=1.0e6,\n",
    "    freq_points_initial=13,\n",
    "    window_delay_span=30e-9,\n",
    "    window_length_factors=(0.7, 0.85, 1.0, 1.15, 1.3),\n",
    "    readout_lengths=(0.5, 0.7, 0.9, 1.0, 1.2, 1.4),\n",
    "    freq_span_mid=250e3,\n",
    "    freq_points_mid=11,\n",
    "    amp_frac=0.2,\n",
    "    amp_points=13,\n",
    "    freq_span_short=80e3,\n",
    "    freq_points_short=9,\n",
    "    count_freq=1024*2,\n",
    "    count_other=512,\n",
    "    do_plot=True,\n",
    "    plot_iq_cloud=True,\n",
    ")\n",
    "\n",
    "_print_history(readout_history)\n",
    "\n",
    "print(\"final readout state (candidate):\")\n",
    "pprint(readout_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395940ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: apply candidate state to q (in-memory only)\n",
    "# NOTE: not yet persisted to qpu YAML unless you save(qpu, ...) later.\n",
    "\n",
    "apply = False  # <- True로 바꿔서 바로 반영\n",
    "\n",
    "if apply:\n",
    "    for k, v in readout_state.items():\n",
    "        if hasattr(q.parameters, k):\n",
    "            setattr(q.parameters, k, v)\n",
    "    print(\"Applied to q.parameters:\", {k: getattr(q.parameters, k) for k in readout_state})\n",
    "else:\n",
    "    print(\"apply=True 를 눌러야 q.parameters에 반영됩니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa1ff6b",
   "metadata": {},
   "source": [
    "# SAVE QPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a68bec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from laboneq.serializers import save, load, from_dict, from_json, to_dict, to_json\n",
    "import time\n",
    "\n",
    "t = time.localtime()\n",
    "timestamp = time.strftime('%Y%m%d-%H%M', t)\n",
    "\n",
    "filename = \"save_test2\"\n",
    "save(qpu, filename=f\"./qpu_parameters/{timestamp}_{filename}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
