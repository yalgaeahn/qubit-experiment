{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3aafbeb",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ef6606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck\n",
      "LOADED: ./qpu_parameters/20260221-0955_readout_opt\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from laboneq.contrib.example_helpers.generate_descriptor import generate_descriptor\n",
    "#from laboneq.contrib.example_helpers.generate_device_setup import generate_device_setup\n",
    "from laboneq.dsl.device import DeviceSetup\n",
    "from laboneq.simple import *\n",
    "from laboneq.dsl.device import DeviceSetup\n",
    "from laboneq.dsl.calibration import Oscillator, SignalCalibration\n",
    "from laboneq.dsl.enums import ModulationType\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# descriptor = generate_descriptor(\n",
    "#     #pqsc=[\"\"], # 장비 여러개 사용시\n",
    "#     shfqc_6=[\"DEV12256\"], \n",
    "#     number_data_qubits=3,\n",
    "#     multiplex=True,\n",
    "#     number_multiplex=6,\n",
    "#     include_cr_lines=False,\n",
    "#     include_ef_lines=True,\n",
    "#     get_zsync=False,  # Only set to True when using real device\n",
    "#     save = True,\n",
    "#     filename=\"1port\",\n",
    "#     ip_address=\"192.168.0.83\"\n",
    "# )\n",
    "\n",
    "\n",
    "#descriptor\n",
    "#setup = DeviceSetup.from_descriptor(yaml_text=descriptor, server_host=\"192.168.0.83\")\n",
    "descriptor_candidates = [\n",
    "    Path(\"examples/selectiveRIP/Descriptors/1port.yaml\"),\n",
    "    Path(\"Descriptors/1port.yaml\"),\n",
    "]\n",
    "descriptor_path = next((p for p in descriptor_candidates if p.exists()), descriptor_candidates[0])\n",
    "setup = DeviceSetup.from_yaml(filepath=str(descriptor_path.resolve()), server_host=\"192.168.0.83\")\n",
    "#setup\n",
    "setup.instruments[0].device_options = 'SHFQC/PLUS/QC6CH'\n",
    "#setup.instruments\n",
    "\n",
    "\n",
    "bus_ids = [f\"b{i}\" for i in range(3)]\n",
    "bus_port = [4,5,6] #used 1,2,3 for qubit drive\n",
    "\n",
    "for i, bus in zip(bus_port,bus_ids):\n",
    "    setup.add_connections(\n",
    "        setup.instruments[0].uid,\n",
    "        # each bus uses its own drive:\n",
    "        create_connection(\n",
    "            to_signal=f\"{bus}/drive\",\n",
    "            ports=f\"SGCHANNELS/{i}/OUTPUT\"\n",
    "        ))\n",
    "\n",
    "# Calibrate qubit drive/measure lines for oscillator phase increments\n",
    "qubit_ids = [uid for uid in setup.logical_signal_groups if uid.startswith(\"q\")]\n",
    "for qubit in qubit_ids:\n",
    "    for line, frequency, mod_type in [\n",
    "        (\"drive\", 5e9, ModulationType.HARDWARE),\n",
    "        (\"drive_ef\", 6e9, ModulationType.HARDWARE),\n",
    "        (\"measure\", 4e9, ModulationType.SOFTWARE),\n",
    "    ]:\n",
    "        logical_signal = setup.logical_signal_by_uid(f\"{qubit}/{line}\")\n",
    "        oscillator = Oscillator(modulation_type=mod_type)\n",
    "        logical_signal.calibration = SignalCalibration(\n",
    "            local_oscillator=Oscillator(frequency=frequency),\n",
    "            oscillator=oscillator,\n",
    "        )\n",
    "        if line == \"measure\":\n",
    "            acquire_signal = setup.logical_signal_by_uid(f\"{qubit}/acquire\")\n",
    "            acquire_signal.calibration = SignalCalibration(\n",
    "                local_oscillator=Oscillator(frequency=frequency),\n",
    "                oscillator=oscillator,\n",
    "            )\n",
    "\n",
    "project_root = next(\n",
    "    (p for p in [Path.cwd(), *Path.cwd().parents] if (p / \"qpu_types\").exists() and (p / \"helper.py\").exists()),\n",
    "    Path.cwd(),\n",
    ")\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from qpu_types.fixed_transmon import FixedTransmonQubit, FixedTransmonQubitParameters\n",
    "from qpu_types.bus_cavity import BusCavity, BusCavityParameters\n",
    "from qpu_types.fixed_transmon.operations import FixedTransmonOperations\n",
    "from qpu_types.bus_cavity.operations import BusCavityOperations\n",
    "from laboneq.dsl.quantum.qpu import QPU, QuantumPlatform\n",
    "from helper import load_qubit_parameters, save_qubit_parameters\n",
    "\n",
    "qubit_uids = [uid for uid in setup.logical_signal_groups if uid.startswith(\"q\")]\n",
    "bus_uids = [uid for uid in setup.logical_signal_groups if uid.startswith(\"b\")]\n",
    "\n",
    "qubits = FixedTransmonQubit.from_device_setup(\n",
    "    setup, qubit_uids=qubit_uids)\n",
    "buses = BusCavity.from_device_setup(\n",
    "    setup, qubit_uids=bus_uids)\n",
    "\n",
    "qpu = QPU(quantum_elements={\"qubits\" : qubits, \"bus\" : buses}, quantum_operations=[FixedTransmonOperations, BusCavityOperations])\n",
    "\n",
    "\n",
    "# from laboneq.simple import workflow\n",
    "# folder_store = workflow.logbook.FolderStore(\"./experiment_store\") \n",
    "# folder_store.activate()\n",
    "# #folder_store.deactivate()\n",
    "# #workflow.logbook.LoggingStore().activate()\n",
    "# #workflow.logbook.LogbookStore().deactivate()\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "def find_latest_json(folder_path):\n",
    "    files = [f for f in os.listdir(folder_path)]\n",
    "    timestamps = []\n",
    "    for file in files:\n",
    "        try:\n",
    "            # Extract a timestamp assuming it's included in the filename\n",
    "            timestamp_str = file.split('_', 1)[0]  # Assuming YYYYMMDDHHMMSS format\n",
    "            timestamp = datetime.strptime(timestamp_str, '%Y%m%d-%H%M%S')\n",
    "            timestamps.append((timestamp, file))\n",
    "        except ValueError:\n",
    "            print(\"fuck\")\n",
    "            continue  # Skip files that do not match the timestamp format\n",
    "\n",
    "       # Find the most recent file\n",
    "    if timestamps:\n",
    "        latest_file = max(timestamps, key=lambda x: x[0])[1]\n",
    "        return os.path.join(folder_path, latest_file)\n",
    "    return None\n",
    "\n",
    "qb_pars_file = find_latest_json(\"./qpu_parameters/\")\n",
    "print(f\"LOADED: {qb_pars_file}\")\n",
    "\n",
    "from qpu_types.fixed_transmon.operations import FixedTransmonOperations\n",
    "from qpu_types.bus_cavity.operations import BusCavityOperations\n",
    "import laboneq.dsl.quantum.qpu as qpu_mod\n",
    "\n",
    "class CombinedOperations(FixedTransmonOperations, BusCavityOperations):\n",
    "    pass\n",
    "\n",
    "qpu_mod.CombinedOperations = CombinedOperations\n",
    "\n",
    "qpu = load(qb_pars_file)\n",
    "\n",
    "buses = qpu.groups.bus\n",
    "qubits = qpu.groups.qubits\n",
    "\n",
    "\n",
    "from laboneq.simple import workflow\n",
    "folder_store = workflow.logbook.FolderStore(\"./experiment_store\")\n",
    "folder_store.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b748a371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026.02.21 09:55:53.416] INFO    Logging initialized from [Default inline config in laboneq.laboneq_logging] logdir is /Users/yalgaeahn/Research/code/qubit-experiment/examples/selectiveRIP/laboneq_output/log\n",
      "[2026.02.21 09:55:53.419] INFO    VERSION: laboneq 25.10.3\n",
      "[2026.02.21 09:55:53.420] INFO    Connecting to data server at 192.168.0.83:8004\n",
      "[2026.02.21 09:55:53.473] INFO    Connected to Zurich Instruments LabOne Data Server version 25.10.1.4 at 192.168.0.83:8004\n",
      "[2026.02.21 09:55:53.610] INFO    Configuring the device setup\n",
      "[2026.02.21 09:55:53.833] INFO    The device setup is configured\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<laboneq.dsl.session.ConnectionState at 0x11fa34530>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from laboneq.simple import Session\n",
    "session = Session(setup)\n",
    "session.connect(ignore_version_mismatch=False, do_emulation=False)\n",
    "#session.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0196ec64",
   "metadata": {},
   "source": [
    "# Multiplexed IQ cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1da5a39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('measure',\n",
       " {'amplitude': 0.522,\n",
       "  'length': 8.192000000000001e-07,\n",
       "  'pulse': {'function': 'GaussianSquare',\n",
       "   'risefall_sigma_ratio': 3.0,\n",
       "   'sigma': 0.03}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qubits[0].readout_integration_parameters()\n",
    "qubits[0].readout_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4800d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026.02.21 09:58:46.790] INFO    \u001b[1m ────────────────────────────────────────────────────────────────────────────── \u001b[0m\n",
      "[2026.02.21 09:58:46.791] INFO    \u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mWorkflow 'iq_cloud': execution started at 2026-02-21 00:58:46.789703Z\u001b[0m\u001b[1m       \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\n",
      "[2026.02.21 09:58:46.791] INFO    \u001b[1m ────────────────────────────────────────────────────────────────────────────── \u001b[0m\n",
      "[2026.02.21 09:58:46.803] INFO    \u001b[1mTask 'temporary_qpu': started at 2026-02-21 00:58:46.803374Z\u001b[0m\n",
      "[2026.02.21 09:58:46.804] INFO    \u001b[1mTask 'temporary_qpu': ended at 2026-02-21 00:58:46.804764Z\u001b[0m\n",
      "[2026.02.21 09:58:46.808] INFO    \u001b[1mTask 'temporary_quantum_elements_from_qpu': started at 2026-02-21 \u001b[0m\n",
      "[2026.02.21 09:58:46.809] INFO    \u001b[1m00:58:46.807989Z\u001b[0m\n",
      "[2026.02.21 09:58:46.811] INFO    \u001b[1mTask 'temporary_quantum_elements_from_qpu': ended at 2026-02-21 00:58:46.811534Z\u001b[0m\n",
      "[2026.02.21 09:58:46.818] INFO    \u001b[1mTask 'create_experiment': started at 2026-02-21 00:58:46.817354Z\u001b[0m\n",
      "[2026.02.21 09:58:46.837] INFO    \u001b[1mTask 'create_experiment': ended at 2026-02-21 00:58:46.837635Z\u001b[0m\n",
      "[2026.02.21 09:58:46.839] INFO    \u001b[1mTask 'compile_experiment': started at 2026-02-21 00:58:46.839532Z\u001b[0m\n",
      "[2026.02.21 09:58:46.841] ERROR   \u001b[1mTask 'compile_experiment': failed at 2026-02-21 00:58:46.841119Z with: \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026.02.21 09:58:46.841] ERROR   \u001b[1mTask 'compile_experiment': failed at 2026-02-21 00:58:46.841119Z with: \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026.02.21 09:58:46.841] ERROR   \u001b[1mLabOneQException(\"The experiment signals q0/acquire, q1/acquire all touch \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026.02.21 09:58:46.841] ERROR   \u001b[1mLabOneQException(\"The experiment signals q0/acquire, q1/acquire all touch \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026.02.21 09:58:46.842] ERROR   \u001b[1mphysical channel 'SHFQC_DEV12256/qachannels_0_input', but provide conflicting \u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026.02.21 09:58:46.842] ERROR   \u001b[1mphysical channel 'SHFQC_DEV12256/qachannels_0_input', but provide conflicting \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026.02.21 09:58:46.842] ERROR   \u001b[1msettings for calibration field 'port_delay'.\")\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2026.02.21 09:58:46.842] ERROR   \u001b[1msettings for calibration field 'port_delay'.\")\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026.02.21 09:58:46.844] INFO    \u001b[1mTask 'compile_experiment': ended at 2026-02-21 00:58:46.843902Z\u001b[0m\n",
      "[2026.02.21 09:58:46.845] INFO    \u001b[1m ────────────────────────────────────────────────────────────────────────────── \u001b[0m\n",
      "[2026.02.21 09:58:46.846] INFO    \u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mWorkflow 'iq_cloud': execution ended at 2026-02-21 00:58:46.845166Z\u001b[0m\u001b[1m         \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\n",
      "[2026.02.21 09:58:46.847] INFO    \u001b[1m ────────────────────────────────────────────────────────────────────────────── \u001b[0m\n"
     ]
    },
    {
     "ename": "LabOneQException",
     "evalue": "The experiment signals q0/acquire, q1/acquire all touch physical channel 'SHFQC_DEV12256/qachannels_0_input', but provide conflicting settings for calibration field 'port_delay'.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLabOneQException\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     16\u001b[39m options.update(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m#options.count(1024)\u001b[39;00m\n\u001b[32m     19\u001b[39m iq_result = \u001b[43miq_cloud\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexperiment_workflow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqpu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mqpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mqubits\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43mqq\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemporary_parameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemporary_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/workflow/core.py:221\u001b[39m, in \u001b[36mWorkflow.run\u001b[39m\u001b[34m(self, until)\u001b[39m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m logstore \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._logstores():\n\u001b[32m    218\u001b[39m     state.add_recorder(\n\u001b[32m    219\u001b[39m         logstore.create_logbook(\u001b[38;5;28mself\u001b[39m, start_time=state.start_time)\n\u001b[32m    220\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/workflow/core.py:131\u001b[39m, in \u001b[36mWorkflow._execute\u001b[39m\u001b[34m(self, state)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m executor.ExecutorStateContext.scoped(state):\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_root\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recovery \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/workflow/blocks/workflow_block.py:159\u001b[39m, in \u001b[36mWorkflowBlock.execute\u001b[39m\u001b[34m(self, executor)\u001b[39m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m executor.get_block_status(block) \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m    155\u001b[39m         ExecutionStatus.FINISHED,\n\u001b[32m    156\u001b[39m         ExecutionStatus.SKIPPED,\n\u001b[32m    157\u001b[39m     ):\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[43mblock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m body_loop_finished = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    161\u001b[39m executor.set_block_status(\u001b[38;5;28mself\u001b[39m, ExecutionStatus.FINISHED)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/workflow/blocks/task_block.py:61\u001b[39m, in \u001b[36mTaskBlock.execute\u001b[39m\u001b[34m(self, executor)\u001b[39m\n\u001b[32m     59\u001b[39m     \u001b[38;5;28mself\u001b[39m._exucute_hidden(executor)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_visible\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/workflow/blocks/task_block.py:91\u001b[39m, in \u001b[36mTaskBlock._execute_visible\u001b[39m\u001b[34m(self, executor)\u001b[39m\n\u001b[32m     89\u001b[39m executor.set_block_status(\u001b[38;5;28mself\u001b[39m, ExecutionStatus.IN_PROGRESS)\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     task._output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m     93\u001b[39m     task._end_time = utc_now()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/workflow/tasks/compile_experiment.py:58\u001b[39m, in \u001b[36mcompile_experiment\u001b[39m\u001b[34m(session, experiment, options)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A task to compile the specified experiment for a given setup.\u001b[39;00m\n\u001b[32m     41\u001b[39m \n\u001b[32m     42\u001b[39m \u001b[33;03mThis task is used to prepare a LabOne Q DSL experiment for execution on a quantum\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m \u001b[33;03m        The `laboneq` compiled experiment.\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     57\u001b[39m opts = CompileExperimentOptions() \u001b[38;5;28;01mif\u001b[39;00m options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m options\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompiler_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/dsl/session.py:392\u001b[39m, in \u001b[36mSession.compile\u001b[39m\u001b[34m(self, experiment, compiler_settings)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compiles the specified experiment and stores it in the compiled_experiment property.\u001b[39;00m\n\u001b[32m    384\u001b[39m \n\u001b[32m    385\u001b[39m \u001b[33;03mRequires connected LabOne Q session (`session.connect()`) either with or without emulation mode.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    389\u001b[39m \u001b[33;03m    compiler_settings: Extra options passed to the compiler.\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    391\u001b[39m \u001b[38;5;28mself\u001b[39m._experiment_definition = experiment\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m \u001b[38;5;28mself\u001b[39m._compiled_experiment = \u001b[43mlaboneq_compile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice_setup\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice_setup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompiler_settings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28mself\u001b[39m._last_results = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_experiment\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/core/utilities/laboneq_compile.py:33\u001b[39m, in \u001b[36mlaboneq_compile\u001b[39m\u001b[34m(device_setup, experiment, compiler_settings)\u001b[39m\n\u001b[32m     30\u001b[39m signal_mapping = convert_signal_map(experiment)\n\u001b[32m     32\u001b[39m payload_builder = PayloadBuilder()\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m payload = \u001b[43mpayload_builder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild_payload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_setup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnew_experiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43msignal_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiler_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m compiled_experiment = CompiledExperiment(\n\u001b[32m     41\u001b[39m     device_setup=device_setup,\n\u001b[32m     42\u001b[39m     experiment=experiment,\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     scheduled_experiment=payload.scheduled_experiment,\n\u001b[32m     46\u001b[39m )\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m compiled_experiment\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/implementation/payload_builder/payload_builder.py:42\u001b[39m, in \u001b[36mPayloadBuilder.build_payload\u001b[39m\u001b[34m(self, device_setup, experiment, signal_mappings, compiler_settings)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_payload\u001b[39m(\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     34\u001b[39m     device_setup: Setup,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     compiler_settings: \u001b[38;5;28mdict\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     38\u001b[39m ) -> ExecutionPayload:\n\u001b[32m     39\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[33;03m    Compose an experiment from a setup descriptor and an experiment descriptor.\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     job = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcreate_compilation_job\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice_setup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal_mappings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompiler_settings\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     scheduled_experiment = _compile(job)\n\u001b[32m     46\u001b[39m     target_setup = TargetSetupGenerator.from_setup(device_setup)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/implementation/payload_builder/payload_builder.py:75\u001b[39m, in \u001b[36mPayloadBuilder.create_compilation_job\u001b[39m\u001b[34m(self, device_setup, experiment, signal_mappings, compiler_settings)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_compilation_job\u001b[39m(\n\u001b[32m     69\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     70\u001b[39m     device_setup: Setup,\n\u001b[32m   (...)\u001b[39m\u001b[32m     73\u001b[39m     compiler_settings: \u001b[38;5;28mdict\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     74\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     experiment_info = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_experiment_info\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_setup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal_mappings\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     execution = ExecutionFactoryFromExperiment().make(experiment)\n\u001b[32m     79\u001b[39m     job = CompilationJob(\n\u001b[32m     80\u001b[39m         experiment_info=experiment_info,\n\u001b[32m     81\u001b[39m         execution=execution,\n\u001b[32m     82\u001b[39m         compiler_settings=compiler_settings,\n\u001b[32m     83\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/implementation/payload_builder/payload_builder.py:66\u001b[39m, in \u001b[36mPayloadBuilder._extract_experiment_info\u001b[39m\u001b[34m(cls, exp, setup, signal_mappings)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_extract_experiment_info\u001b[39m(\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     63\u001b[39m     signal_mappings: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[32m     64\u001b[39m ) -> ExperimentInfo:\n\u001b[32m     65\u001b[39m     builder = ExperimentInfoBuilder(exp, setup, signal_mappings)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/implementation/payload_builder/experiment_info_builder/experiment_info_builder.py:117\u001b[39m, in \u001b[36mExperimentInfoBuilder.load_experiment\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_experiment\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> ExperimentInfo:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_physical_channel_calibration_conflict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m signal \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._experiment.signals:\n\u001b[32m    119\u001b[39m         \u001b[38;5;28mself\u001b[39m._load_signal(signal)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Research/code/qubit-experiment/.venv/lib/python3.12/site-packages/laboneq/implementation/payload_builder/experiment_info_builder/experiment_info_builder.py:219\u001b[39m, in \u001b[36mExperimentInfoBuilder._check_physical_channel_calibration_conflict\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    207\u001b[39m     conflicting_signals = [\n\u001b[32m    208\u001b[39m         exp_signal.uid\n\u001b[32m    209\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m exp_signal \u001b[38;5;129;01min\u001b[39;00m exp_signals\n\u001b[32m   (...)\u001b[39m\u001b[32m    216\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(other_signal_cal, field_) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    217\u001b[39m     ]\n\u001b[32m    218\u001b[39m     pc_uid = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpc_group\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LabOneQException(\n\u001b[32m    220\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe experiment signals \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(conflicting_signals)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m all \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    221\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtouch physical channel \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpc_uid\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, but provide conflicting \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    222\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msettings for calibration field \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfield_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    223\u001b[39m     )\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m unique_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    225\u001b[39m     \u001b[38;5;66;03m# Make sure all the experiment signals agree.\u001b[39;00m\n\u001b[32m    226\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m exp_signal \u001b[38;5;129;01min\u001b[39;00m exp_signals:\n",
      "\u001b[31mLabOneQException\u001b[39m: The experiment signals q0/acquire, q1/acquire all touch physical channel 'SHFQC_DEV12256/qachannels_0_input', but provide conflicting settings for calibration field 'port_delay'."
     ]
    }
   ],
   "source": [
    "from experiments import iq_cloud_common, iq_cloud\n",
    "q = qubits[0]\n",
    "qq = qubits[1]\n",
    "\n",
    "temporary_parameters = {}\n",
    "q_temp_pars = deepcopy(q.parameters)\n",
    "qq_temp_pars = deepcopy(qq.parameters)\n",
    "qq_temp_pars.readout_integration_delay = 250e-9\n",
    "#q_temp_pars.readout_integration_delay = 250e-9\n",
    "temporary_parameters[q.uid] = q_temp_pars\n",
    "temporary_parameters[qq.uid] = qq_temp_pars\n",
    "#######################################################################\n",
    "\n",
    "options = iq_cloud.experiment_workflow.options()\n",
    "options.do_analysis(True)\n",
    "options.update(False)\n",
    "#options.count(1024)\n",
    "\n",
    "iq_result = iq_cloud.experiment_workflow(\n",
    "    session=session,\n",
    "    qpu=qpu,\n",
    "    qubits=[q,qq],\n",
    "    temporary_parameters=temporary_parameters,\n",
    "    options=options,\n",
    ").run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ae126b",
   "metadata": {},
   "source": [
    "## INTEGRATION Pipeline Validation (New)\n",
    "\n",
    "아래 셀은 **DISCRIMINATION 경로 없이** `INTEGRATION + SINGLE_SHOT` 기반으로\\n\n",
    "`two_qubit_readout_calibration` -> `two_qubit_state_tomography` 분석이 동작하는지 검증합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac0cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(qubits[0].parameters.readout_resonator_frequency)\n",
    "print(qubits[1].parameters.readout_resonator_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ae6136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments import two_qubit_readout_calibration\n",
    "from experiments import two_qubit_state_tomography\n",
    "import numpy as np\n",
    "\n",
    "# Reuse existing variables from notebook: session, qpu, ctrl, targ, bus, temporary_parameters\n",
    "if \"ctrl\" not in globals() or \"targ\" not in globals():\n",
    "    ctrl = qubits[1]\n",
    "    targ = qubits[0]\n",
    "if \"bus\" not in globals():\n",
    "    bus = buses[0]\n",
    "if \"temporary_parameters\" not in globals():\n",
    "    temporary_parameters = {}\n",
    "\n",
    "bus = buses[0]\n",
    "def unwrap_output(obj):\n",
    "    cur = obj\n",
    "    for _ in range(24):\n",
    "        if hasattr(cur, \"output\"):\n",
    "            cur = cur.output\n",
    "            continue\n",
    "        return cur\n",
    "    return cur\n",
    "\n",
    "\n",
    "def _is_reference_like(obj):\n",
    "    return obj is not None and obj.__class__.__name__ == \"Reference\"\n",
    "\n",
    "\n",
    "def _contains_reference(obj, depth=0, max_depth=12):\n",
    "    if depth > max_depth:\n",
    "        return False\n",
    "    cur = unwrap_output(obj)\n",
    "    if _is_reference_like(cur):\n",
    "        return True\n",
    "    if isinstance(cur, dict):\n",
    "        return any(_contains_reference(v, depth + 1, max_depth) for v in cur.values())\n",
    "    if isinstance(cur, (list, tuple)):\n",
    "        return any(_contains_reference(v, depth + 1, max_depth) for v in cur)\n",
    "    return False\n",
    "\n",
    "\n",
    "def _iter_tasks(node):\n",
    "    tasks = getattr(node, \"tasks\", None)\n",
    "    if tasks is None:\n",
    "        return []\n",
    "    try:\n",
    "        return list(tasks)\n",
    "    except Exception:\n",
    "        return []\n",
    "\n",
    "\n",
    "def _task_output(tasks, key):\n",
    "    try:\n",
    "        out = unwrap_output(tasks[key].output)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if _is_reference_like(out):\n",
    "        return None\n",
    "    return out\n",
    "\n",
    "\n",
    "def _assemble_from_analysis_tasks(analysis_node):\n",
    "    tasks = getattr(analysis_node, \"tasks\", None)\n",
    "    if tasks is None:\n",
    "        return None\n",
    "\n",
    "    assignment = _task_output(tasks, \"extract_assignment_matrix\")\n",
    "    tomography_counts = _task_output(tasks, \"collect_tomography_counts\")\n",
    "    mle = _task_output(tasks, \"maximum_likelihood_reconstruct\")\n",
    "    state_metrics = _task_output(tasks, \"calculate_state_metrics\")\n",
    "    discriminator = _task_output(tasks, \"fit_discriminator_from_readout_calibration\")\n",
    "\n",
    "    if not all(isinstance(x, dict) for x in [assignment, tomography_counts, mle, state_metrics, discriminator]):\n",
    "        return None\n",
    "\n",
    "    assembled = {\n",
    "        \"assignment_matrix\": assignment.get(\"assignment_matrix\"),\n",
    "        \"assignment_counts\": assignment.get(\"counts_matrix_soft\"),\n",
    "        \"assignment_counts_soft\": assignment.get(\"counts_matrix_soft\"),\n",
    "        \"assignment_counts_hard\": assignment.get(\"counts_matrix_hard\"),\n",
    "        \"tomography_counts\": tomography_counts.get(\"counts\"),\n",
    "        \"tomography_counts_hard\": tomography_counts.get(\"counts_hard\"),\n",
    "        \"setting_labels\": tomography_counts.get(\"setting_labels\"),\n",
    "        \"shots_per_setting\": tomography_counts.get(\"shots_per_setting\"),\n",
    "        \"rho_hat_real\": mle.get(\"rho_hat_real\"),\n",
    "        \"rho_hat_imag\": mle.get(\"rho_hat_imag\"),\n",
    "        \"predicted_probabilities\": mle.get(\"predicted_probabilities\"),\n",
    "        \"predicted_counts\": mle.get(\"predicted_counts\"),\n",
    "        \"optimizer_success\": mle.get(\"optimizer_success\"),\n",
    "        \"optimizer_message\": mle.get(\"optimizer_message\"),\n",
    "        \"negative_log_likelihood\": mle.get(\"negative_log_likelihood\"),\n",
    "        \"metrics\": state_metrics,\n",
    "        \"discriminator_model\": discriminator.get(\"model\"),\n",
    "        \"classification_diagnostics\": discriminator.get(\"diagnostics\"),\n",
    "        \"bitflip_ctrl\": False,\n",
    "        \"bitflip_targ\": False,\n",
    "    }\n",
    "    return assembled\n",
    "\n",
    "\n",
    "def _find_analysis_node(root, depth=0, max_depth=12):\n",
    "    if root is None or depth > max_depth:\n",
    "        return None\n",
    "    tasks = _iter_tasks(root)\n",
    "    if tasks:\n",
    "        names = {getattr(t, \"name\", \"\") for t in tasks}\n",
    "        if \"maximum_likelihood_reconstruct\" in names and \"extract_assignment_matrix\" in names:\n",
    "            return root\n",
    "        for t in tasks:\n",
    "            found = _find_analysis_node(t, depth + 1, max_depth)\n",
    "            if found is not None:\n",
    "                return found\n",
    "            found = _find_analysis_node(getattr(t, \"output\", None), depth + 1, max_depth)\n",
    "            if found is not None:\n",
    "                return found\n",
    "    out = getattr(root, \"output\", None)\n",
    "    if out is not None and out is not root:\n",
    "        return _find_analysis_node(out, depth + 1, max_depth)\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_analysis_output(workflow_result):\n",
    "    analysis_node = _find_analysis_node(workflow_result)\n",
    "    if analysis_node is None:\n",
    "        raise RuntimeError(\"Could not locate analysis workflow node.\")\n",
    "\n",
    "    out = unwrap_output(getattr(analysis_node, \"output\", None))\n",
    "    if isinstance(out, dict) and not _contains_reference(out):\n",
    "        return out\n",
    "\n",
    "    assembled = _assemble_from_analysis_tasks(analysis_node)\n",
    "    if isinstance(assembled, dict):\n",
    "        return assembled\n",
    "\n",
    "    raise RuntimeError(\"Could not materialize concrete analysis output from workflow tasks.\")\n",
    "\n",
    "\n",
    "# 1) Readout calibration acquisition (INTEGRATION + SINGLE_SHOT fixed by module)\n",
    "readout_cal_result_new = two_qubit_readout_calibration.experiment_workflow(\n",
    "    session=session,\n",
    "    qpu=qpu,\n",
    "    ctrl=ctrl,\n",
    "    targ=targ,\n",
    "    temporary_parameters=temporary_parameters,\n",
    ").run()\n",
    "\n",
    "# 2) 2Q tomography with external readout calibration result\n",
    "tomo_opts_new = two_qubit_state_tomography.experiment_workflow.options()\n",
    "tomo_opts_new.do_analysis(True)\n",
    "tomo_opts_new.do_readout_calibration(False)\n",
    "\n",
    "bus_frequency = (\n",
    "    bus.parameters.resonance_frequency_bus + (bus.parameters.rip_detuning or 0.0)\n",
    "    if bus.parameters.resonance_frequency_bus is not None\n",
    "    else 6.5e9\n",
    ")\n",
    "rip_amplitude = float(getattr(bus.parameters, \"rip_amplitude\", 0.0) or 0.0)\n",
    "rip_length = float(getattr(bus.parameters, \"rip_length\", 64e-9) or 64e-9)\n",
    "\n",
    "twoq_qst_result_new = two_qubit_state_tomography.experiment_workflow(\n",
    "    session=session,\n",
    "    qpu=qpu,\n",
    "    ctrl=ctrl,\n",
    "    targ=targ,\n",
    "    bus=bus,\n",
    "    bus_frequency=bus_frequency,\n",
    "    rip_amplitude=rip_amplitude,\n",
    "    rip_length=rip_length,\n",
    "    rip_phase=np.pi / 2,\n",
    "    readout_calibration_result=readout_cal_result_new,\n",
    "    target_state=\"++\",\n",
    "    options=tomo_opts_new,\n",
    "    temporary_parameters=temporary_parameters,\n",
    ").run()\n",
    "\n",
    "out_new = unwrap_output(twoq_qst_result_new.output)\n",
    "analysis_new = extract_analysis_output(twoq_qst_result_new)\n",
    "\n",
    "print(\"top-level task names:\", [t.name for t in twoq_qst_result_new.tasks])\n",
    "print(\"workflow output type:\", type(out_new).__name__)\n",
    "print(\"analysis keys:\", list(analysis_new.keys()))\n",
    "print(\"fidelity_to_target:\", analysis_new[\"metrics\"].get(\"fidelity_to_target\"))\n",
    "print(\"classifier diagnostics:\", analysis_new.get(\"classification_diagnostics\", {}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6be8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "A_soft = np.asarray(analysis_new[\"assignment_matrix\"], dtype=float)\n",
    "C_soft = np.asarray(analysis_new[\"assignment_counts_soft\"], dtype=float)\n",
    "C_hard = np.asarray(analysis_new[\"assignment_counts_hard\"], dtype=float)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4.2))\n",
    "\n",
    "im0 = axes[0].imshow(A_soft, vmin=0.0, vmax=1.0, cmap=\"Blues\")\n",
    "axes[0].set_title(\"Assignment matrix (soft)\")\n",
    "axes[0].set_xlabel(\"Prepared k\")\n",
    "axes[0].set_ylabel(\"Measured i\")\n",
    "axes[0].set_xticks(range(4), [\"00\", \"01\", \"10\", \"11\"])\n",
    "axes[0].set_yticks(range(4), [\"00\", \"01\", \"10\", \"11\"])\n",
    "fig.colorbar(im0, ax=axes[0], fraction=0.046)\n",
    "\n",
    "im1 = axes[1].imshow(C_soft, cmap=\"viridis\")\n",
    "axes[1].set_title(\"Calibration counts (soft)\")\n",
    "axes[1].set_xlabel(\"Prepared k\")\n",
    "axes[1].set_ylabel(\"Measured i\")\n",
    "axes[1].set_xticks(range(4), [\"00\", \"01\", \"10\", \"11\"])\n",
    "axes[1].set_yticks(range(4), [\"00\", \"01\", \"10\", \"11\"])\n",
    "fig.colorbar(im1, ax=axes[1], fraction=0.046)\n",
    "\n",
    "im2 = axes[2].imshow(C_hard, cmap=\"viridis\")\n",
    "axes[2].set_title(\"Calibration counts (hard, argmax)\")\n",
    "axes[2].set_xlabel(\"Prepared k\")\n",
    "axes[2].set_ylabel(\"Measured i\")\n",
    "axes[2].set_xticks(range(4), [\"00\", \"01\", \"10\", \"11\"])\n",
    "axes[2].set_yticks(range(4), [\"00\", \"01\", \"10\", \"11\"])\n",
    "fig.colorbar(im2, ax=axes[2], fraction=0.046)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b953e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a93106fe",
   "metadata": {},
   "source": [
    "## QST Validation Suite (Pass/Fail)\n",
    "\n",
    "아래 셀은 `analysis_new`(또는 workflow 결과)로부터 2Q QST가 정상 동작하는지 자동 검증합니다.\n",
    "- Assignment matrix 정규화/대각 우세\n",
    "- Tomography counts 무결성\n",
    "- 재구성 density matrix 물리성(Hermitian/trace/PSD)\n",
    "- target fidelity 범위\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77356325",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def _fmt_bool(x):\n",
    "    return 'PASS' if bool(x) else 'FAIL'\n",
    "\n",
    "def validate_twoq_qst_analysis(analysis_dict, *, tol=1e-6):\n",
    "    A = np.asarray(analysis_dict['assignment_matrix'], dtype=float)\n",
    "    C_soft = np.asarray(analysis_dict['assignment_counts_soft'], dtype=float)\n",
    "    C_hard = np.asarray(analysis_dict['assignment_counts_hard'], dtype=float)\n",
    "    T_soft = np.asarray(analysis_dict['tomography_counts'], dtype=float)\n",
    "    T_hard = np.asarray(analysis_dict['tomography_counts_hard'], dtype=float)\n",
    "    shots = np.asarray(analysis_dict['shots_per_setting'], dtype=float)\n",
    "    setting_labels = list(analysis_dict['setting_labels'])\n",
    "\n",
    "    rho = np.asarray(analysis_dict['rho_hat_real'], dtype=float) + 1j*np.asarray(analysis_dict['rho_hat_imag'], dtype=float)\n",
    "\n",
    "    checks = {}\n",
    "\n",
    "    checks['assignment_shape_4x4'] = (A.shape == (4, 4))\n",
    "    row_sums = A.sum(axis=1) if A.shape == (4, 4) else np.array([np.nan])\n",
    "    checks['assignment_rows_sum_to_1'] = np.all(np.isfinite(row_sums)) and np.allclose(row_sums, 1.0, atol=5e-3)\n",
    "    checks['assignment_diagonal_better_than_random'] = (np.trace(A)/4.0) > 0.25 if A.shape == (4, 4) else False\n",
    "\n",
    "    checks['counts_nonnegative_finite'] = (\n",
    "        np.all(np.isfinite(C_soft)) and np.all(np.isfinite(C_hard)) and\n",
    "        np.all(np.isfinite(T_soft)) and np.all(np.isfinite(T_hard)) and\n",
    "        np.all(C_soft >= -tol) and np.all(C_hard >= -tol) and\n",
    "        np.all(T_soft >= -tol) and np.all(T_hard >= -tol)\n",
    "    )\n",
    "\n",
    "    checks['tomography_row_sum_matches_shots'] = (\n",
    "        T_soft.shape[0] == shots.shape[0] and np.allclose(T_soft.sum(axis=1), shots, atol=max(1e-6, 5e-3*np.max(shots)))\n",
    "    )\n",
    "    checks['settings_count_consistent'] = (T_soft.shape[0] == len(setting_labels))\n",
    "\n",
    "    checks['rho_shape_4x4'] = (rho.shape == (4, 4))\n",
    "    herm_err = np.linalg.norm(rho - rho.conj().T) if rho.shape == (4, 4) else np.inf\n",
    "    checks['rho_hermitian'] = herm_err < 1e-8\n",
    "    tr = np.trace(rho) if rho.shape == (4, 4) else np.nan\n",
    "    checks['rho_trace_1'] = np.isfinite(np.real(tr)) and abs(np.real(tr) - 1.0) < 1e-6\n",
    "    min_eig = float(np.min(np.linalg.eigvalsh((rho + rho.conj().T)/2.0)).real) if rho.shape == (4, 4) else -np.inf\n",
    "    checks['rho_psd'] = min_eig > -1e-6\n",
    "\n",
    "    fidelity = analysis_dict.get('metrics', {}).get('fidelity_to_target', None)\n",
    "    checks['fidelity_in_range_or_none'] = (fidelity is None) or (0.0 <= float(fidelity) <= 1.0)\n",
    "\n",
    "    summary = {\n",
    "        'assignment_avg_diag': float(np.trace(A)/4.0),\n",
    "        'assignment_row_sums': row_sums.tolist(),\n",
    "        'hermitian_error': float(herm_err),\n",
    "        'rho_trace_real': float(np.real(tr)),\n",
    "        'rho_min_eigenvalue': float(min_eig),\n",
    "        'fidelity_to_target': None if fidelity is None else float(fidelity),\n",
    "        'num_settings': int(T_soft.shape[0]),\n",
    "        'shots_minmax': (float(np.min(shots)), float(np.max(shots))) if shots.size else (np.nan, np.nan),\n",
    "    }\n",
    "\n",
    "    overall_pass = all(bool(v) for v in checks.values())\n",
    "    return checks, summary, overall_pass\n",
    "\n",
    "analysis_for_validation = analysis_new if 'analysis_new' in globals() else extract_analysis_output(twoq_qst_result_new)\n",
    "checks, summary, overall_pass = validate_twoq_qst_analysis(analysis_for_validation)\n",
    "\n",
    "print('=== 2Q QST Validation Summary ===')\n",
    "for k, v in checks.items():\n",
    "    print(f'{_fmt_bool(v):4s} | {k}')\n",
    "print('----------------------------------')\n",
    "print('overall:', _fmt_bool(overall_pass))\n",
    "print('assignment_avg_diag:', f\"{summary['assignment_avg_diag']:.4f}\")\n",
    "print('assignment_row_sums:', np.round(summary['assignment_row_sums'], 4))\n",
    "print('rho_trace_real:', f\"{summary['rho_trace_real']:.8f}\")\n",
    "print('rho_min_eigenvalue:', f\"{summary['rho_min_eigenvalue']:.3e}\")\n",
    "print('fidelity_to_target:', summary['fidelity_to_target'])\n",
    "print('num_settings:', summary['num_settings'], 'shots[min,max]:', summary['shots_minmax'])\n",
    "print('classifier diagnostics:', analysis_for_validation.get('classification_diagnostics', {}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556666e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.asarray(analysis_new[\"assignment_matrix\"], dtype=float)\n",
    "print(\"col sums:\", A.sum(axis=0))  # 이게 1에 가까워야 정상\n",
    "print(\"row sums:\", A.sum(axis=1))  # 필수 조건 아님\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b411bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional repeatability check (set RUN_REPEAT = True to execute)\n",
    "RUN_REPEAT = False\n",
    "N_REPEAT = 3\n",
    "\n",
    "if RUN_REPEAT:\n",
    "    fids = []\n",
    "    min_eigs = []\n",
    "    diag_avgs = []\n",
    "    pass_flags = []\n",
    "\n",
    "    for rep in range(N_REPEAT):\n",
    "        qst_rep = two_qubit_state_tomography.experiment_workflow(\n",
    "            session=session,\n",
    "            qpu=qpu,\n",
    "            ctrl=ctrl,\n",
    "            targ=targ,\n",
    "            bus=bus,\n",
    "            bus_frequency=bus_frequency,\n",
    "            rip_amplitude=rip_amplitude,\n",
    "            rip_length=rip_length,\n",
    "            rip_phase=np.pi/2,\n",
    "            readout_calibration_result=readout_cal_result_new,\n",
    "            target_state='++',\n",
    "            options=tomo_opts_new,\n",
    "            temporary_parameters=temporary_parameters,\n",
    "        ).run()\n",
    "\n",
    "        an_rep = extract_analysis_output(qst_rep)\n",
    "        checks_rep, summary_rep, ok_rep = validate_twoq_qst_analysis(an_rep)\n",
    "\n",
    "        pass_flags.append(bool(ok_rep))\n",
    "        diag_avgs.append(float(summary_rep['assignment_avg_diag']))\n",
    "        min_eigs.append(float(summary_rep['rho_min_eigenvalue']))\n",
    "        fid = summary_rep['fidelity_to_target']\n",
    "        if fid is not None:\n",
    "            fids.append(float(fid))\n",
    "\n",
    "        print(f'Rep {rep+1}/{N_REPEAT}:', 'PASS' if ok_rep else 'FAIL',\n",
    "              'diag=', f\"{summary_rep['assignment_avg_diag']:.4f}\",\n",
    "              'min_eig=', f\"{summary_rep['rho_min_eigenvalue']:.3e}\",\n",
    "              'fid=', summary_rep['fidelity_to_target'])\n",
    "\n",
    "    print('\\n=== Repeatability Summary ===')\n",
    "    print('pass_rate:', f\"{np.mean(pass_flags):.3f}\")\n",
    "    print('assignment_avg_diag: mean/std =', f\"{np.mean(diag_avgs):.4f}\", '/', f\"{np.std(diag_avgs):.4f}\")\n",
    "    print('rho_min_eigenvalue: mean/std =', f\"{np.mean(min_eigs):.3e}\", '/', f\"{np.std(min_eigs):.3e}\")\n",
    "    if len(fids) > 0:\n",
    "        print('fidelity_to_target: mean/std =', f\"{np.mean(fids):.4f}\", '/', f\"{np.std(fids):.4f}\")\n",
    "else:\n",
    "    print('Set RUN_REPEAT = True to execute repeatability check.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bced8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1ff205a",
   "metadata": {},
   "source": [
    "## Validation Mode Example (No RIP)\n",
    "\n",
    "아래 셀은 `validation_mode=True`로 RIP 없이 `initial_state=\"++\"`를 준비하고,\n",
    "`target_state`는 자동으로 `++`로 맞춘 뒤 reconstructed density matrix를 ideal `++`와 비교합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066a0ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = buses[0]\n",
    "bus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676045ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from experiments import two_qubit_state_tomography\n",
    "\n",
    "# Reuse existing variables if present\n",
    "# if \"ctrl\" not in globals() or \"targ\" not in globals():\n",
    "#     ctrl = qubits[1]\n",
    "#     targ = qubits[0]\n",
    "# if \"bus\" not in globals():\n",
    "#     bus = buses[0]\n",
    "# if \"temporary_parameters\" not in globals():\n",
    "#     temporary_parameters = {}\n",
    "\n",
    "# Use existing readout calibration result when available\n",
    "readout_cal_for_val = None\n",
    "if \"readout_cal_result_new\" in globals():\n",
    "    readout_cal_for_val = readout_cal_result_new\n",
    "\n",
    "opts_val = two_qubit_state_tomography.experiment_workflow.options()\n",
    "opts_val.do_analysis(True)\n",
    "opts_val.do_readout_calibration(True)\n",
    "opts_val.validation_mode(True)\n",
    "opts_val.use_rip(True)              # validation_mode=True 이면 자동으로 RIP 미사용\n",
    "opts_val.initial_state(\"++\")\n",
    "opts_val.enforce_target_match(True)\n",
    "\n",
    "bus_frequency = (\n",
    "    bus.parameters.resonance_frequency_bus + (bus.parameters.rip_detuning or 0.0)\n",
    "    if bus.parameters.resonance_frequency_bus is not None\n",
    "    else 6.5e9\n",
    ")\n",
    "rip_amplitude = float(getattr(bus.parameters, \"rip_amplitude\", 0.0) or 0.0)\n",
    "rip_length = float(getattr(bus.parameters, \"rip_length\", 64e-9) or 64e-9)\n",
    "\n",
    "wf_val = two_qubit_state_tomography.experiment_workflow(\n",
    "    session=session,\n",
    "    qpu=qpu,\n",
    "    ctrl=ctrl,\n",
    "    targ=targ,\n",
    "    bus=bus,\n",
    "    bus_frequency=bus_frequency,\n",
    "    rip_amplitude=rip_amplitude,\n",
    "    rip_length=rip_length,\n",
    "    rip_phase=np.pi/2,\n",
    "    readout_calibration_result=readout_cal_for_val,\n",
    "    target_state=None,\n",
    "    options=opts_val,\n",
    "    temporary_parameters=temporary_parameters,\n",
    ").run()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90795d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_val = extract_analysis_output(wf_val)\n",
    "rho_hat = np.asarray(analysis_val[\"rho_hat_real\"], dtype=float) + 1j*np.asarray(analysis_val[\"rho_hat_imag\"], dtype=float)\n",
    "rho_hat = (rho_hat + rho_hat.conj().T) / 2.0\n",
    "rho_hat /= np.trace(rho_hat)\n",
    "\n",
    "psi_pp = np.array([1,1,1,1], dtype=complex) / 2.0\n",
    "rho_ideal = np.outer(psi_pp, psi_pp.conj())\n",
    "fidelity_pp = float(np.real(np.conjugate(psi_pp) @ rho_hat @ psi_pp))\n",
    "\n",
    "print(\"validation_mode:\", unwrap_output(wf_val.output).get(\"validation_mode\", \"n/a\"))\n",
    "print(\"used_rip:\", unwrap_output(wf_val.output).get(\"used_rip\", \"n/a\"))\n",
    "print(\"target_state_effective:\", unwrap_output(wf_val.output).get(\"target_state_effective\", \"n/a\"))\n",
    "print(\"fidelity_to_++:\", fidelity_pp)\n",
    "\n",
    "labels = [\"|00>\",\"|01>\",\"|10>\",\"|11>\"]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4.0))\n",
    "im0 = axes[0].imshow(rho_ideal.real, vmin=-0.5, vmax=0.5, cmap=\"RdBu_r\")\n",
    "axes[0].set_title(\"Ideal Re[rho] for ++\")\n",
    "axes[0].set_xticks(range(4), labels, rotation=45)\n",
    "axes[0].set_yticks(range(4), labels)\n",
    "\n",
    "im1 = axes[1].imshow(rho_hat.real, vmin=-0.5, vmax=0.5, cmap=\"RdBu_r\")\n",
    "axes[1].set_title(\"Reconstructed Re[rho]\")\n",
    "axes[1].set_xticks(range(4), labels, rotation=45)\n",
    "axes[1].set_yticks(range(4), labels)\n",
    "\n",
    "fig.colorbar(im1, ax=axes.ravel().tolist(), fraction=0.035)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111abcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7dc01a7a",
   "metadata": {},
   "source": [
    "## Convergence Validation (Product State Suite)\n",
    "\n",
    "이 섹션은 optimization convergence + statistical convergence를 함께 확인합니다.\n",
    "statistical suite는 현재 pulse 지원 범위에 맞춰 `00, 01, 10, 11, ++`만 사용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3271998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: run convergence suite workflow\n",
    "RUN_CONVERGENCE_SUITE = True\n",
    "CONVERGENCE_REPEATS = 3\n",
    "CONVERGENCE_STATES = (\"00\", \"01\", \"10\", \"11\", \"++\")\n",
    "\n",
    "if RUN_CONVERGENCE_SUITE:\n",
    "    tomo_opts_conv = two_qubit_state_tomography.experiment_workflow.options()\n",
    "    tomo_opts_conv.do_analysis(True)\n",
    "    tomo_opts_conv.do_readout_calibration(False)\n",
    "    tomo_opts_conv.do_convergence_validation(True)\n",
    "    tomo_opts_conv.convergence_repeats_per_state(CONVERGENCE_REPEATS)\n",
    "    tomo_opts_conv.convergence_suite_states(CONVERGENCE_STATES)\n",
    "    tomo_opts_conv.convergence_do_plotting(True)\n",
    "\n",
    "    twoq_qst_conv_result = two_qubit_state_tomography.experiment_workflow(\n",
    "        session=session,\n",
    "        qpu=qpu,\n",
    "        ctrl=ctrl,\n",
    "        targ=targ,\n",
    "        bus=bus,\n",
    "        bus_frequency=bus_frequency,\n",
    "        rip_amplitude=rip_amplitude,\n",
    "        rip_length=rip_length,\n",
    "        rip_phase=np.pi / 2,\n",
    "        readout_calibration_result=readout_cal_result_new,\n",
    "        target_state=\"++\",\n",
    "        options=tomo_opts_conv,\n",
    "        temporary_parameters=temporary_parameters,\n",
    "    ).run()\n",
    "    print(\"Convergence suite run finished.\")\n",
    "else:\n",
    "    print(\"Set RUN_CONVERGENCE_SUITE = True to execute convergence suite.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f378682d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_convergence_report(workflow_result):\n",
    "    out = unwrap_output(getattr(workflow_result, \"output\", workflow_result))\n",
    "    if isinstance(out, dict) and \"convergence_report\" in out and not _contains_reference(out[\"convergence_report\"]):\n",
    "        return out[\"convergence_report\"]\n",
    "\n",
    "    report = {}\n",
    "    stack = [workflow_result]\n",
    "    seen = set()\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        if node is None:\n",
    "            continue\n",
    "        nid = id(node)\n",
    "        if nid in seen:\n",
    "            continue\n",
    "        seen.add(nid)\n",
    "\n",
    "        for t in _iter_tasks(node):\n",
    "            name = getattr(t, \"name\", \"\")\n",
    "            if name == \"resolve_convergence_suite_states\":\n",
    "                report[\"suite_states\"] = tuple(unwrap_output(getattr(t, \"output\", None)) or ())\n",
    "            elif name == \"summarize_statistical_convergence\":\n",
    "                report[\"statistical_convergence\"] = unwrap_output(getattr(t, \"output\", None))\n",
    "            elif name == \"extract_main_run_optimization_convergence\":\n",
    "                report[\"main_run_optimization_convergence\"] = unwrap_output(getattr(t, \"output\", None))\n",
    "            elif name == \"collect_convergence_run_record\":\n",
    "                report.setdefault(\"raw_run_records\", []).append(unwrap_output(getattr(t, \"output\", None)))\n",
    "            stack.append(t)\n",
    "            stack.append(getattr(t, \"output\", None))\n",
    "\n",
    "        stack.append(getattr(node, \"output\", None))\n",
    "\n",
    "    if \"raw_run_records\" in report:\n",
    "        report[\"raw_run_records\"] = [r for r in report[\"raw_run_records\"] if isinstance(r, dict)]\n",
    "    if \"raw_run_records\" in report and \"suite_states\" in report and report[\"suite_states\"]:\n",
    "        n_states = max(1, len(report[\"suite_states\"]))\n",
    "        report[\"repeats_per_state\"] = int(len(report[\"raw_run_records\"]) / n_states)\n",
    "    return report\n",
    "\n",
    "if \"twoq_qst_conv_result\" in globals():\n",
    "    convergence_report = extract_convergence_report(twoq_qst_conv_result)\n",
    "    print(\"Convergence report keys:\", list(convergence_report.keys()))\n",
    "    main_opt = convergence_report.get(\"main_run_optimization_convergence\", {})\n",
    "    if isinstance(main_opt, dict):\n",
    "        print(\"main optimizer_success:\", main_opt.get(\"optimizer_success\"))\n",
    "        print(\"main nll_per_shot:\", main_opt.get(\"nll_per_shot\"))\n",
    "        print(\"main mae_counts:\", main_opt.get(\"mae_counts\"))\n",
    "else:\n",
    "    print(\"Run the convergence suite cell first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884ee227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if \"convergence_report\" not in globals():\n",
    "    print(\"No convergence_report available.\")\n",
    "else:\n",
    "    stat = convergence_report.get(\"statistical_convergence\", {})\n",
    "    per_state = stat.get(\"per_state\", {}) if isinstance(stat, dict) else {}\n",
    "    agg = stat.get(\"aggregate\", {}) if isinstance(stat, dict) else {}\n",
    "\n",
    "    print(\"=== Per-state statistical convergence ===\")\n",
    "    header = \"state | runs | opt_success | fid_mean±std | fid_ci95 | nll_mean±std | min_eig_mean | min_eig_min\"\n",
    "    print(header)\n",
    "    print(\"-\" * len(header))\n",
    "    for state in sorted(per_state.keys()):\n",
    "        s = per_state[state]\n",
    "        print(\n",
    "            f\"{state:>4s} | {s.get('num_runs', 0):>4d} | {s.get('optimizer_success_rate', 0.0):>10.3f} | \"\n",
    "            f\"{s.get('fidelity_mean')} ± {s.get('fidelity_std')} | {s.get('fidelity_ci95')} | \"\n",
    "            f\"{s.get('nll_mean')} ± {s.get('nll_std')} | {s.get('rho_min_eigenvalue_mean')} | {s.get('rho_min_eigenvalue_min')}\"\n",
    "        )\n",
    "\n",
    "    print(\"\\n=== Aggregate statistical convergence ===\")\n",
    "    for k in [\n",
    "        \"num_total_runs\",\n",
    "        \"overall_optimizer_success_rate\",\n",
    "        \"pooled_fidelity_mean\",\n",
    "        \"pooled_fidelity_std\",\n",
    "        \"pooled_fidelity_ci95\",\n",
    "        \"worst_rho_min_eigenvalue\",\n",
    "    ]:\n",
    "        print(f\"{k}: {agg.get(k)}\")\n",
    "\n",
    "    states = sorted(per_state.keys())\n",
    "    if states:\n",
    "        means = np.array([per_state[s].get(\"fidelity_mean\") if per_state[s].get(\"fidelity_mean\") is not None else np.nan for s in states], dtype=float)\n",
    "        errs = np.array([per_state[s].get(\"fidelity_ci95\") if per_state[s].get(\"fidelity_ci95\") is not None else np.nan for s in states], dtype=float)\n",
    "        fig, ax = plt.subplots(figsize=(7.2, 3.8))\n",
    "        x = np.arange(len(states))\n",
    "        ax.errorbar(x, means, yerr=errs, fmt=\"o\", capsize=4)\n",
    "        ax.set_xticks(x, states)\n",
    "        ax.set_ylim(0.0, 1.05)\n",
    "        ax.set_ylabel(\"Fidelity\")\n",
    "        ax.set_title(\"Product-state suite fidelity mean ± 95% CI\")\n",
    "        ax.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e39685",
   "metadata": {},
   "source": [
    "### Scope Note\n",
    "\n",
    "이 convergence suite는 현재 Product cardinal subset(`00, 01, 10, 11, ++`)만 포함합니다.\n",
    "Bell-state statistical convergence는 Bell preparation pulse가 추가된 뒤 확장합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5855ab0",
   "metadata": {},
   "source": [
    "## Shot Sweep: Product-State Target Infidelity\n",
    "\n",
    "`shots = 2^k (k=3..12)`에서 product state suite(`00, 01, 10, 11, ++`)의 target-state infidelity(`1 - fidelity_to_target`)를 측정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7d5b2fd4",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(20260222)\n",
    "\n",
    "SHOT_LOG2_VALUES = list(range(3, 13))\n",
    "SHOT_COUNTS = [2 ** k for k in SHOT_LOG2_VALUES]\n",
    "PRODUCT_SUITE_STATES = (\"00\", \"01\", \"10\", \"11\", \"++\")\n",
    "REPEATS_PER_POINT = 3\n",
    "EPS = 1e-12\n",
    "INFID_TOL = 1e-9\n",
    "\n",
    "expected_total_runs = len(PRODUCT_SUITE_STATES) * len(SHOT_COUNTS) * REPEATS_PER_POINT\n",
    "\n",
    "print(\"shot grid (log2):\", SHOT_LOG2_VALUES)\n",
    "print(\"shot counts:\", SHOT_COUNTS)\n",
    "print(\"states:\", PRODUCT_SUITE_STATES)\n",
    "print(\"repeats per point:\", REPEATS_PER_POINT)\n",
    "print(\"expected total runs:\", expected_total_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "b0a036cd",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "if \"readout_cal_result_new\" not in globals():\n",
    "    raise RuntimeError(\"readout_cal_result_new not found. Run readout calibration cell first.\")\n",
    "if \"extract_analysis_output\" not in globals():\n",
    "    raise RuntimeError(\"extract_analysis_output function not found. Run QST setup cell first.\")\n",
    "if \"temporary_parameters\" not in globals():\n",
    "    temporary_parameters = {}\n",
    "if \"ctrl\" not in globals() or \"targ\" not in globals():\n",
    "    ctrl = qubits[1]\n",
    "    targ = qubits[0]\n",
    "if \"bus\" not in globals():\n",
    "    bus = buses[0]\n",
    "\n",
    "bus_frequency = (\n",
    "    bus.parameters.resonance_frequency_bus + (bus.parameters.rip_detuning or 0.0)\n",
    "    if bus.parameters.resonance_frequency_bus is not None\n",
    "    else 6.5e9\n",
    ")\n",
    "rip_amplitude = float(getattr(bus.parameters, \"rip_amplitude\", 0.0) or 0.0)\n",
    "rip_length = float(getattr(bus.parameters, \"rip_length\", 64e-9) or 64e-9)\n",
    "\n",
    "\n",
    "def _to_float_or_nan(value):\n",
    "    try:\n",
    "        v = float(value)\n",
    "        return v if np.isfinite(v) else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "sweep_rows = []\n",
    "failed_runs = []\n",
    "run_counter = 0\n",
    "\n",
    "for state in PRODUCT_SUITE_STATES:\n",
    "    for log2_shots, shots in zip(SHOT_LOG2_VALUES, SHOT_COUNTS):\n",
    "        for repeat in range(1, REPEATS_PER_POINT + 1):\n",
    "            run_counter += 1\n",
    "            print(\n",
    "                f\"[{run_counter:03d}/{expected_total_runs}] \"\n",
    "                f\"state={state}, shots={shots}, repeat={repeat}\"\n",
    "            )\n",
    "\n",
    "            tomo_opts_sweep = two_qubit_state_tomography.experiment_workflow.options()\n",
    "            tomo_opts_sweep.do_analysis(True)\n",
    "            tomo_opts_sweep.do_readout_calibration(False)\n",
    "            tomo_opts_sweep.validation_mode(True)\n",
    "            tomo_opts_sweep.use_rip(False)\n",
    "            tomo_opts_sweep.initial_state(state)\n",
    "            tomo_opts_sweep.enforce_target_match(True)\n",
    "            tomo_opts_sweep.count(int(shots))\n",
    "\n",
    "            try:\n",
    "                run_result = two_qubit_state_tomography.experiment_workflow(\n",
    "                    session=session,\n",
    "                    qpu=qpu,\n",
    "                    ctrl=ctrl,\n",
    "                    targ=targ,\n",
    "                    bus=bus,\n",
    "                    bus_frequency=bus_frequency,\n",
    "                    rip_amplitude=rip_amplitude,\n",
    "                    rip_length=rip_length,\n",
    "                    rip_phase=np.pi / 2,\n",
    "                    readout_calibration_result=readout_cal_result_new,\n",
    "                    target_state=state,\n",
    "                    options=tomo_opts_sweep,\n",
    "                    temporary_parameters=temporary_parameters,\n",
    "                ).run()\n",
    "                analysis = extract_analysis_output(run_result)\n",
    "            except Exception as exc:\n",
    "                failed_runs.append(\n",
    "                    {\n",
    "                        \"state\": state,\n",
    "                        \"log2_shots\": log2_shots,\n",
    "                        \"shots\": shots,\n",
    "                        \"repeat\": repeat,\n",
    "                        \"reason\": repr(exc),\n",
    "                    }\n",
    "                )\n",
    "                sweep_rows.append(\n",
    "                    {\n",
    "                        \"state\": state,\n",
    "                        \"log2_shots\": log2_shots,\n",
    "                        \"shots\": shots,\n",
    "                        \"repeat\": repeat,\n",
    "                        \"fidelity\": np.nan,\n",
    "                        \"infidelity\": np.nan,\n",
    "                        \"log10_infidelity\": np.nan,\n",
    "                        \"nll\": np.nan,\n",
    "                        \"min_eig\": np.nan,\n",
    "                    }\n",
    "                )\n",
    "                print(\"  -> failed:\", repr(exc))\n",
    "                continue\n",
    "\n",
    "            metrics = analysis.get(\"metrics\", {}) if isinstance(analysis, dict) else {}\n",
    "            fid_raw = metrics.get(\"fidelity_to_target\")\n",
    "            nll_raw = analysis.get(\"negative_log_likelihood\") if isinstance(analysis, dict) else np.nan\n",
    "            min_eig_raw = metrics.get(\"min_eigenvalue\")\n",
    "\n",
    "            fid = _to_float_or_nan(fid_raw)\n",
    "            if np.isfinite(fid):\n",
    "                infid = max(EPS, 1.0 - fid)\n",
    "                log10_infid = float(np.log10(infid))\n",
    "            else:\n",
    "                infid = np.nan\n",
    "                log10_infid = np.nan\n",
    "                failed_runs.append(\n",
    "                    {\n",
    "                        \"state\": state,\n",
    "                        \"log2_shots\": log2_shots,\n",
    "                        \"shots\": shots,\n",
    "                        \"repeat\": repeat,\n",
    "                        \"reason\": f\"invalid fidelity: {fid_raw!r}\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            sweep_rows.append(\n",
    "                {\n",
    "                    \"state\": state,\n",
    "                    \"log2_shots\": log2_shots,\n",
    "                    \"shots\": shots,\n",
    "                    \"repeat\": repeat,\n",
    "                    \"fidelity\": fid,\n",
    "                    \"infidelity\": infid,\n",
    "                    \"log10_infidelity\": log10_infid,\n",
    "                    \"nll\": _to_float_or_nan(nll_raw),\n",
    "                    \"min_eig\": _to_float_or_nan(min_eig_raw),\n",
    "                }\n",
    "            )\n",
    "\n",
    "shot_sweep_df = pd.DataFrame(\n",
    "    sweep_rows,\n",
    "    columns=[\n",
    "        \"state\",\n",
    "        \"log2_shots\",\n",
    "        \"shots\",\n",
    "        \"repeat\",\n",
    "        \"fidelity\",\n",
    "        \"infidelity\",\n",
    "        \"log10_infidelity\",\n",
    "        \"nll\",\n",
    "        \"min_eig\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Completed rows:\", len(shot_sweep_df))\n",
    "print(\"Failed/invalid runs:\", len(failed_runs))\n",
    "if failed_runs:\n",
    "    display(pd.DataFrame(failed_runs).head(10))\n",
    "\n",
    "display(shot_sweep_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "92c5df38",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "required_cols = [\n",
    "    \"state\",\n",
    "    \"log2_shots\",\n",
    "    \"shots\",\n",
    "    \"repeat\",\n",
    "    \"fidelity\",\n",
    "    \"infidelity\",\n",
    "    \"log10_infidelity\",\n",
    "    \"nll\",\n",
    "    \"min_eig\",\n",
    "]\n",
    "assert list(shot_sweep_df.columns) == required_cols, \"Unexpected dataframe schema.\"\n",
    "\n",
    "counts_by_group = shot_sweep_df.groupby([\"state\", \"log2_shots\"]).size()\n",
    "expected_index = pd.MultiIndex.from_product(\n",
    "    [PRODUCT_SUITE_STATES, SHOT_LOG2_VALUES],\n",
    "    names=[\"state\", \"log2_shots\"],\n",
    ")\n",
    "missing_groups = expected_index.difference(counts_by_group.index)\n",
    "bad_repeat_groups = counts_by_group[counts_by_group != REPEATS_PER_POINT]\n",
    "\n",
    "range_violations = shot_sweep_df[\n",
    "    shot_sweep_df[\"infidelity\"].notna()\n",
    "    & (\n",
    "        (shot_sweep_df[\"infidelity\"] < (EPS - 1e-15))\n",
    "        | (shot_sweep_df[\"infidelity\"] > (1.0 + INFID_TOL))\n",
    "    )\n",
    "]\n",
    "\n",
    "print(\"=== Validation checks ===\")\n",
    "print(\"expected groups:\", len(expected_index))\n",
    "print(\"observed groups:\", len(counts_by_group))\n",
    "print(\"missing groups:\", len(missing_groups))\n",
    "print(\"groups with wrong repeat count:\", len(bad_repeat_groups))\n",
    "print(\"infidelity range violations:\", len(range_violations))\n",
    "\n",
    "counts_matrix = counts_by_group.unstack(level=1).reindex(PRODUCT_SUITE_STATES)\n",
    "display(counts_matrix)\n",
    "\n",
    "if len(missing_groups) > 0:\n",
    "    print(\"Missing groups:\", list(missing_groups)[:10])\n",
    "if len(bad_repeat_groups) > 0:\n",
    "    print(\"Bad repeat groups:\")\n",
    "    display(bad_repeat_groups)\n",
    "if len(range_violations) > 0:\n",
    "    print(\"Range violations (first 10):\")\n",
    "    display(range_violations.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3738b8ce",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _finite_stats(series):\n",
    "    arr = pd.to_numeric(series, errors=\"coerce\").to_numpy(dtype=float)\n",
    "    arr = arr[np.isfinite(arr)]\n",
    "    n = arr.size\n",
    "    if n == 0:\n",
    "        return {\n",
    "            \"n\": 0,\n",
    "            \"mean\": np.nan,\n",
    "            \"std\": np.nan,\n",
    "            \"sem\": np.nan,\n",
    "            \"ci95\": np.nan,\n",
    "        }\n",
    "    mean = float(np.mean(arr))\n",
    "    std = float(np.std(arr, ddof=1)) if n > 1 else 0.0\n",
    "    sem = float(std / np.sqrt(n)) if n > 1 else 0.0\n",
    "    ci95 = float(1.96 * sem) if n > 1 else 0.0\n",
    "    return {\n",
    "        \"n\": int(n),\n",
    "        \"mean\": mean,\n",
    "        \"std\": std,\n",
    "        \"sem\": sem,\n",
    "        \"ci95\": ci95,\n",
    "    }\n",
    "\n",
    "\n",
    "agg_rows = []\n",
    "for (state, log2_shots), group in shot_sweep_df.groupby([\"state\", \"log2_shots\"], sort=True):\n",
    "    inf_stats = _finite_stats(group[\"infidelity\"])\n",
    "    log_stats = _finite_stats(group[\"log10_infidelity\"])\n",
    "    agg_rows.append(\n",
    "        {\n",
    "            \"state\": state,\n",
    "            \"log2_shots\": int(log2_shots),\n",
    "            \"shots\": int(group[\"shots\"].iloc[0]),\n",
    "            \"n_total\": int(len(group)),\n",
    "            \"n_valid_infidelity\": inf_stats[\"n\"],\n",
    "            \"infid_mean\": inf_stats[\"mean\"],\n",
    "            \"infid_std\": inf_stats[\"std\"],\n",
    "            \"infid_sem\": inf_stats[\"sem\"],\n",
    "            \"infid_ci95\": inf_stats[\"ci95\"],\n",
    "            \"log10_infid_mean\": log_stats[\"mean\"],\n",
    "            \"log10_infid_std\": log_stats[\"std\"],\n",
    "            \"log10_infid_sem\": log_stats[\"sem\"],\n",
    "            \"log10_infid_ci95\": log_stats[\"ci95\"],\n",
    "        }\n",
    "    )\n",
    "\n",
    "shot_sweep_stats = pd.DataFrame(agg_rows).sort_values([\"state\", \"log2_shots\"]).reset_index(drop=True)\n",
    "display(shot_sweep_stats.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "115ae795",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5.5))\n",
    "\n",
    "for state in PRODUCT_SUITE_STATES:\n",
    "    state_df = shot_sweep_stats[shot_sweep_stats[\"state\"] == state].sort_values(\"log2_shots\")\n",
    "    x = state_df[\"log2_shots\"].to_numpy(dtype=float)\n",
    "\n",
    "    y_infid = state_df[\"infid_mean\"].to_numpy(dtype=float)\n",
    "    e_infid = state_df[\"infid_ci95\"].to_numpy(dtype=float)\n",
    "    mask_infid = np.isfinite(y_infid)\n",
    "    if np.any(mask_infid):\n",
    "        axes[0].plot(x[mask_infid], y_infid[mask_infid], \"o--\", label=f\"|{state}><{state}|\")\n",
    "        low = y_infid[mask_infid] - np.nan_to_num(e_infid[mask_infid], nan=0.0)\n",
    "        high = y_infid[mask_infid] + np.nan_to_num(e_infid[mask_infid], nan=0.0)\n",
    "        axes[0].fill_between(x[mask_infid], low, high, alpha=0.2)\n",
    "\n",
    "    y_log = state_df[\"log10_infid_mean\"].to_numpy(dtype=float)\n",
    "    e_log = state_df[\"log10_infid_ci95\"].to_numpy(dtype=float)\n",
    "    mask_log = np.isfinite(y_log)\n",
    "    if np.any(mask_log):\n",
    "        axes[1].plot(x[mask_log], y_log[mask_log], \"o--\", label=f\"|{state}><{state}|\")\n",
    "        low = y_log[mask_log] - np.nan_to_num(e_log[mask_log], nan=0.0)\n",
    "        high = y_log[mask_log] + np.nan_to_num(e_log[mask_log], nan=0.0)\n",
    "        axes[1].fill_between(x[mask_log], low, high, alpha=0.2)\n",
    "\n",
    "axes[0].set_title(\"Infidelity vs Log(Number of shots)\")\n",
    "axes[0].set_xlabel(\"Log(Number of shots) = log2(shots)\")\n",
    "axes[0].set_ylabel(\"Infidelity\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[0].legend(fontsize=9)\n",
    "\n",
    "axes[1].set_title(\"Log10(Infidelity) vs Log(Number of shots)\")\n",
    "axes[1].set_xlabel(\"Log(Number of shots) = log2(shots)\")\n",
    "axes[1].set_ylabel(\"Log10(Infidelity)\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[1].legend(fontsize=9)\n",
    "\n",
    "fig.suptitle(\"2Q QST Product-State Suite Shot Sweep (k=3..12)\", y=1.02, fontsize=14)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "a1fef5fa",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "last_log2 = max(SHOT_LOG2_VALUES)\n",
    "last_shots = 2 ** last_log2\n",
    "\n",
    "final_summary = (\n",
    "    shot_sweep_stats[shot_sweep_stats[\"log2_shots\"] == last_log2][\n",
    "        [\n",
    "            \"state\",\n",
    "            \"n_total\",\n",
    "            \"n_valid_infidelity\",\n",
    "            \"infid_mean\",\n",
    "            \"infid_ci95\",\n",
    "            \"log10_infid_mean\",\n",
    "            \"log10_infid_ci95\",\n",
    "        ]\n",
    "    ]\n",
    "    .sort_values(\"state\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(f\"Final-shot summary at log2(shots)={last_log2} (shots={last_shots})\")\n",
    "display(final_summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}